import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import os


# === 1. Êõ¥Êñ∞ÂêéÁöÑÁΩëÁªúÁªìÊûÑ (ÈúÄ‰∏éËÆ≠ÁªÉËÑöÊú¨‰∏ÄËá¥) ===
class BetterCNN(nn.Module):
    def __init__(self):
        super(BetterCNN, self).__init__()

        # Á¨¨‰∏ÄÂ±ÇÂç∑ÁßØÂùó: Conv -> BatchNorm -> ReLU -> MaxPool
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)  # Êñ∞Â¢ûÂ±Ç

        # Á¨¨‰∫åÂ±ÇÂç∑ÁßØÂùó
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)  # Êñ∞Â¢ûÂ±Ç

        self.pool = nn.MaxPool2d(2, 2)
        self.relu = nn.ReLU()

        # ÂÖ®ËøûÊé•Â±Ç
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.dropout = nn.Dropout(0.5)  # Êñ∞Â¢ûÂ±Ç
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        # Block 1
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.pool(x)

        # Block 2
        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.pool(x)

        # Flatten
        x = x.view(-1, 64 * 7 * 7)

        # FC Block
        x = self.fc1(x)
        x = self.relu(x)
        # Ê≥®ÊÑèÔºöÊé®ÁêÜÊó∂ model.eval() ‰ºöËá™Âä®ÂÖ≥Èó≠ dropoutÔºåËøôÈáå‰øùÁïôÁªìÊûÑÂç≥ÂèØ
        x = self.dropout(x)
        x = self.fc2(x)
        return x


# === 2. Ê®°ÂûãÁºìÂ≠ò‰∏éÂä†ËΩΩ ===
_MODELS = {}
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def get_model(dataset_name):
    if dataset_name in _MODELS: return _MODELS[dataset_name]

    try:
        if dataset_name == 'dataset_A':
            print("üì• Âä†ËΩΩ MNIST ‰ºòÂåñÁâàÊ®°Âûã (dataset_A)...")
            # --- ‰øÆÊîπÁÇπÔºöÂÆû‰æãÂåñ BetterCNN ---
            model = BetterCNN().to(device)
            # Âä†ËΩΩÂèÇÊï∞
            model.load_state_dict(torch.load("models/model_a.pth", map_location=device, weights_only=True))
            model.eval()  # ÂÖ≥ÈîÆÔºÅËøô‰ºöÂÖ≥Èó≠ Dropout Âíå BatchNorm ÁöÑËÆ≠ÁªÉÊ®°Âºè
            _MODELS[dataset_name] = model

        elif dataset_name == 'dataset_B':
            print("üì• Âä†ËΩΩ ResNet18 (dataset_B)...")
            model = models.resnet18(weights='DEFAULT').to(device)
            model.eval()
            _MODELS[dataset_name] = model

        elif dataset_name == 'dataset_C':
            print("üì• Âä†ËΩΩ MobileNetV3 (dataset_C)...")
            model = models.mobilenet_v3_small(weights='DEFAULT').to(device)
            model.eval()
            _MODELS[dataset_name] = model

    except Exception as e:
        print(f"‚ùå Ê®°ÂûãÂä†ËΩΩÂ§±Ë¥•: {e}")
        return None

    return _MODELS.get(dataset_name)


# === 3. Ê†∏ÂøÉÂàÜÁ±ªÂáΩÊï∞ ===
def classify_image(dataset_name, image_path):
    model = get_model(dataset_name)
    if not model: return "Error: Model not loaded"

    try:
        img = Image.open(image_path)

        # È¢ÑÂ§ÑÁêÜ
        if dataset_name == 'dataset_A':
            tf = transforms.Compose([
                transforms.Grayscale(num_output_channels=1),
                transforms.Resize((28, 28)),
                transforms.ToTensor(),
                transforms.Normalize((0.1307,), (0.3081,))
            ])
        else:
            img = img.convert('RGB')
            tf = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])

        img_t = tf(img).unsqueeze(0).to(device)

        # Êé®ÁêÜ
        with torch.no_grad():
            out = model(img_t)
            prob = torch.nn.functional.softmax(out[0], dim=0)
            score, idx = torch.max(prob, 0)
            class_id = idx.item()

        # Êò†Â∞ÑÁ±ªÂà´ ID -> ÂêçÁß∞
        label_file = {
            'dataset_A': 'models/model_a_classes.txt',
            'dataset_B': 'models/model_b_classes.txt',
            'dataset_C': 'models/model_c_classes.txt'
        }.get(dataset_name)

        predicted_label = str(class_id)

        if label_file and os.path.exists(label_file):
            with open(label_file, 'r', encoding='utf-8') as f:
                classes = [line.strip() for line in f.readlines()]
                if class_id < len(classes):
                    predicted_label = classes[class_id]

        return predicted_label

    except Exception as e:
        return f"Error: {str(e)}"


# === 4. Â∑•ÂÖ∑ÂáΩÊï∞ ===
def list_images(dataset_name):
    path = os.path.join("datasets", dataset_name)
    if not os.path.exists(path): return []
    images = []
    for root, _, files in os.walk(path):
        for f in files:
            if f.lower().endswith(('.png', '.jpg', '.jpeg')):
                images.append(os.path.join(root, f).replace('\\', '/'))
    return images


def get_image_data(image_path):
    return image_path