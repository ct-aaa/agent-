import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image, ImageOps  # å¼•å…¥ ImageOps ç”¨äºŽåè‰²
import os

# --- å…¨å±€é…ç½® ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 1. æ¨¡åž‹æ–‡ä»¶é…ç½®
config = {
    "dataset_A": {"model": "model_a.pth", "classes": "model_a_classes.txt"},
    "dataset_B": {"model": "model_b.pth", "classes": "model_b_classes.txt"},
    "dataset_C": {"model": "model_c.pth", "classes": "model_c_classes.txt"}
}

# 2. æž¶æž„é…ç½®
MODEL_ARCH_CONFIG = {
    "dataset_A": "resnet18",
    "dataset_B": "resnet18",
    "dataset_C": "resnet50"
}

_MODEL_CACHE = {}

# 3. é¢„å¤„ç†
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])


def load_model_for_dataset(dataset_name):
    if dataset_name in _MODEL_CACHE:
        return _MODEL_CACHE[dataset_name]

    if dataset_name not in config:
        return None, []

    info = config[dataset_name]
    model_path = os.path.join("models", info["model"])
    txt_path = os.path.join("models", info["classes"])

    if not os.path.exists(model_path) or not os.path.exists(txt_path):
        print(f"âŒ æ–‡ä»¶ç¼ºå¤±: {model_path} æˆ– {txt_path}")
        return None, []

    try:
        # è¯»å–ç±»åˆ«
        with open(txt_path, 'r', encoding='utf-8') as f:
            classes = [line.strip() for line in f.readlines() if line.strip()]

        # åŠ è½½æƒé‡
        checkpoint = torch.load(model_path, map_location=device, weights_only=False)
        state_dict = checkpoint['state_dict'] if (
                    isinstance(checkpoint, dict) and 'state_dict' in checkpoint) else checkpoint

        # æ¸…æ´— Key
        new_state_dict = {}
        for k, v in state_dict.items():
            name = k
            if name.startswith('module.'): name = name[7:]
            if name.startswith('Network.features.'): name = name.replace('Network.features.', '')
            if name.startswith('Network.classifier.'): name = name.replace('Network.classifier.', 'fc.')
            new_state_dict[name] = v

        # æ™ºèƒ½åˆ¤æ–­ç±»åˆ«æ•°
        if 'fc.weight' in new_state_dict:
            model_num_classes = new_state_dict['fc.weight'].shape[0]
        else:
            model_num_classes = len(classes)

        # åˆå§‹åŒ–æ¨¡åž‹
        arch = MODEL_ARCH_CONFIG.get(dataset_name, "resnet18")
        if arch == "resnet50":
            model = models.resnet50(weights=None)
        else:
            model = models.resnet18(weights=None)

        model.fc = nn.Linear(model.fc.in_features, model_num_classes)
        model.load_state_dict(new_state_dict)
        model.to(device)
        model.eval()

        _MODEL_CACHE[dataset_name] = (model, classes)
        return model, classes

    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡åž‹å¤±è´¥ {dataset_name}: {e}")
        return None, []


def list_images(dataset_name):
    path = os.path.join("datasets", dataset_name)
    if not os.path.exists(path): return f"Error: {path} not found"
    images = []
    for root, _, files in os.walk(path):
        for f in files:
            if f.lower().endswith(('.png', '.jpg', '.jpeg')):
                images.append(os.path.join(root, f).replace('\\', '/'))
    return images


def classify_image(image_path):
    if "dataset_A" in image_path:
        ds = "dataset_A"
    elif "dataset_B" in image_path:
        ds = "dataset_B"
    elif "dataset_C" in image_path:
        ds = "dataset_C"
    else:
        return "Error: è·¯å¾„ä¸­æœªåŒ…å« dataset_A/B/C"

    model, classes = load_model_for_dataset(ds)
    if not model: return "Error: æ¨¡åž‹åŠ è½½å¤±è´¥"

    try:
        img = Image.open(image_path).convert('RGB')

        # # === ðŸš‘ å…³é”®ä¿®å¤ï¼šé’ˆå¯¹ Dataset_C çš„è‡ªåŠ¨åè‰² ===
        # if ds == "dataset_C":
        #     # ç®€å•é‡‡æ ·åˆ¤æ–­äº®åº¦ï¼šå¦‚æžœå·¦ä¸Šè§’æ˜¯ç™½è‰²çš„(255)ï¼Œè¯´æ˜Žæ˜¯ç™½åº•é»‘çº¿ï¼Œéœ€è¦åè‰²
        #     # æˆ–è€…ç›´æŽ¥è®¡ç®—å¹³å‡äº®åº¦
        #     from torchvision.transforms.functional import to_tensor
        #     if to_tensor(img).mean() > 0.5:
        #         # print("Detected white background, inverting...")
        #         img = ImageOps.invert(img)
        # # ==========================================

        img_t = transform(img).unsqueeze(0).to(device)

        with torch.no_grad():
            out = model(img_t)
            prob = torch.nn.functional.softmax(out[0], dim=0)
            score, idx = torch.max(prob, 0)

            if idx.item() >= len(classes):
                return f"Error: ç´¢å¼•è¶Šç•Œ"

            return f"{classes[idx.item()]} ({score.item() * 100:.1f}%)"
    except Exception as e:
        return f"Error: {e}"