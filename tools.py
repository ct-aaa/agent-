import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import os


# === 1. è¿™é‡Œçš„ BetterCNN ä»…ç”¨äº Dataset A (MNIST) ===
class BetterCNN(nn.Module):
    def __init__(self):
        super(BetterCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)
        self.pool = nn.MaxPool2d(2, 2)
        self.relu = nn.ReLU()
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.dropout = nn.Dropout(0.5)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.pool(self.relu(self.bn1(self.conv1(x))))
        x = self.pool(self.relu(self.bn2(self.conv2(x))))
        x = x.view(-1, 64 * 7 * 7)
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x


# === 2. æ¨¡å‹ç¼“å­˜ ===
_MODELS = {}
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def get_model(dataset_name):
    if dataset_name in _MODELS: return _MODELS[dataset_name]

    try:
        if dataset_name == 'dataset_A':
            print("ğŸ“¥ åŠ è½½ MNIST æ¨¡å‹ (dataset_A)...")
            model = BetterCNN().to(device)
            # ç¡®ä¿ weights_only=True ä»¥é¿å…è­¦å‘Š
            if os.path.exists("models/model_a.pth"):
                model.load_state_dict(torch.load("models/model_a.pth", map_location=device, weights_only=True))
            else:
                print("âš ï¸ è­¦å‘Š: models/model_a.pth ä¸å­˜åœ¨ï¼Œè¯·å…ˆè®­ç»ƒ Model A")
            model.eval()
            _MODELS[dataset_name] = model

        elif dataset_name == 'dataset_B':

            print("ğŸ“¥ æ­£åœ¨åŠ è½½æœ¬åœ°ç¼“å­˜çš„ CIFAR-10 æ¨¡å‹ (ç¦»çº¿æ¨¡å¼)...")

            # 1. è®¾ç½®ä½ çš„æœ¬åœ°ç¼“å­˜è·¯å¾„ (æ ¹æ®ä½ çš„æŠ¥é”™æˆªå›¾æå–çš„è·¯å¾„)

            # ä½¿ç”¨ r"" é˜²æ­¢åæ–œæ è½¬ä¹‰é—®é¢˜

            hub_dir = r"C:\Users\admin\.cache\torch\hub\chenyaofo_pytorch-cifar-models_master"

            if not os.path.exists(hub_dir):
                print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æœ¬åœ°ç¼“å­˜ç›®å½•: {hub_dir}")
                print("è¯·å…ˆç”¨è”ç½‘æ¨¡å¼è¿è¡Œä¸€æ¬¡ï¼Œæˆ–æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
                return None

            try:

                # 2. æ ¸å¿ƒä¿®æ”¹: source='local'
                # è¿™å‘Šè¯‰ PyTorch ä¸è¦å» GitHub æŸ¥æ›´æ–°ï¼Œç›´æ¥ç”¨ç¡¬ç›˜é‡Œçš„æ–‡ä»¶
                model = torch.hub.load(hub_dir, "cifar10_resnet20", pretrained=True, source='local')
                model = model.to(device)
                model.eval()
                _MODELS[dataset_name] = model
                print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (Local)")


            except Exception as e:
                print(f"âŒ æœ¬åœ°åŠ è½½å¤±è´¥: {e}")
                print("å°è¯•æ£€æŸ¥ cache æ–‡ä»¶å¤¹é‡Œæ˜¯å¦æœ‰ hubconf.py æ–‡ä»¶")
                return None

        elif dataset_name == 'dataset_C':
            print("ğŸ“¥ åŠ è½½ MobileNetV3 (dataset_C)...")
            model = models.mobilenet_v3_small(weights='DEFAULT').to(device)
            model.eval()
            _MODELS[dataset_name] = model

    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

    return _MODELS.get(dataset_name)


# === 3. æ ¸å¿ƒåˆ†ç±»å‡½æ•° ===
def classify_image(dataset_name, image_path):
    model = get_model(dataset_name)
    if not model: return "Error: Model not loaded"

    try:
        img = Image.open(image_path)

        # === é’ˆå¯¹ä¸åŒæ•°æ®é›†ä½¿ç”¨ä¸åŒçš„é¢„å¤„ç† ===
        if dataset_name == 'dataset_A':
            # MNIST: 28x28, ç°åº¦
            tf = transforms.Compose([
                transforms.Grayscale(num_output_channels=1),
                transforms.Resize((28, 28)),
                transforms.ToTensor(),
                transforms.Normalize((0.1307,), (0.3081,))
            ])
        elif dataset_name == 'dataset_B':
            # CIFAR-10: 32x32, RGB, æ ‡å‡†åŒ–å‚æ•°ä¸åŒ
            img = img.convert('RGB')
            tf = transforms.Compose([
                transforms.Resize((32, 32)),  # å…³é”®ï¼šCIFAR æ¨¡å‹éœ€è¦ 32x32
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])
            ])
        else:
            # Dataset C (ImageNet): 224x224
            img = img.convert('RGB')
            tf = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])

        img_t = tf(img).unsqueeze(0).to(device)

        # æ¨ç†
        with torch.no_grad():
            out = model(img_t)
            prob = torch.nn.functional.softmax(out[0], dim=0)
            score, idx = torch.max(prob, 0)
            class_id = idx.item()

        # === ç»“æœæ˜ å°„ ===
        predicted_label = str(class_id)

        if dataset_name == 'dataset_B':
            # CIFAR-10 çš„ç±»åˆ«æ˜¯å›ºå®šçš„ï¼Œæˆ‘ä»¬ç›´æ¥ç¡¬ç¼–ç ï¼Œä¸éœ€è¦è¯» txt æ–‡ä»¶
            # è¿™æ ·æ›´ç¨³å¥
            cifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
            if class_id < len(cifar_classes):
                raw_label = cifar_classes[class_id]
                # å…¼å®¹æ€§å¤„ç†ï¼šæŠŠ standard label è½¬æ¢æˆä½  label.txt é‡Œçš„å«æ³•
                # ä½ çš„ label.txt ç”¨çš„æ˜¯ "car", "plane"
                if raw_label == 'automobile':
                    predicted_label = 'car'
                elif raw_label == 'airplane':
                    predicted_label = 'plane'
                else:
                    predicted_label = raw_label
        else:
            # å…¶ä»–æ¨¡å‹ç»§ç»­è¯»å– txt
            label_file = {
                'dataset_A': 'models/model_a_classes.txt',
                'dataset_C': 'models/model_c_classes.txt'
            }.get(dataset_name)

            if label_file and os.path.exists(label_file):
                with open(label_file, 'r', encoding='utf-8') as f:
                    classes = [line.strip() for line in f.readlines()]
                    if class_id < len(classes):
                        predicted_label = classes[class_id]

        return predicted_label

    except Exception as e:
        return f"Error: {str(e)}"


# === 4. å·¥å…·å‡½æ•° ===
def list_images(dataset_name):
    path = os.path.join("datasets", dataset_name)
    if not os.path.exists(path): return []
    images = []
    for root, _, files in os.walk(path):
        for f in files:
            if f.lower().endswith(('.png', '.jpg', '.jpeg')):
                images.append(os.path.join(root, f).replace('\\', '/'))
    return images


def get_image_data(image_path):
    return image_path