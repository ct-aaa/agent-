import torch
import torch.nn as nn
from torchvision import models, transforms
import os
from PIL import Image, ImageOps, ImageStat # ğŸ‘ˆ å¿…é¡»å¼•å…¥ ImageOps å’Œ ImageStat

# --- å…¨å±€é…ç½® ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 1. æ¨¡å‹æ–‡ä»¶è·¯å¾„é…ç½®
config = {
    "dataset_A": {"model": "model_a.pth", "classes": "model_a_classes.txt"},
    "dataset_B": {"model": "model_b.pth", "classes": "model_b_classes.txt"},
    # æŒ‡å‘ä½ å‡†ç¡®ç‡æœ€é«˜çš„é‚£ä¸ªæ¨¡å‹ (å‡è®¾æ˜¯ finetuned ç‰ˆæœ¬)
    "dataset_C": {"model": "model_c_finetuned.pth", "classes": "model_c_classes.txt"}
}

# 2. æ¨¡å‹æ¶æ„é…ç½®
MODEL_ARCH_CONFIG = {
    "dataset_A": "resnet18",
    "dataset_B": "resnet18",
    "dataset_C": "mobilenet_v3_small"
}

_MODEL_CACHE = {}

# 3. é¢„å¤„ç†
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])


def load_model_for_dataset(dataset_name):
    """åŠ è½½æ¨¡å‹å¹¶ç¼“å­˜"""
    if dataset_name in _MODEL_CACHE:
        return _MODEL_CACHE[dataset_name]

    if dataset_name not in config:
        return None, []

    info = config[dataset_name]
    model_path = os.path.join("models", info["model"])
    txt_path = os.path.join("models", info["classes"])

    if not os.path.exists(model_path) or not os.path.exists(txt_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {model_path} æˆ– {txt_path}")
        return None, []

    try:
        # 1. è¯»å–ç±»åˆ«è¡¨
        with open(txt_path, 'r', encoding='utf-8') as f:
            classes = [line.strip() for line in f.readlines() if line.strip()]

        # 2. åŠ è½½æƒé‡å­—å…¸
        checkpoint = torch.load(model_path, map_location=device, weights_only=False)
        state_dict = checkpoint['state_dict'] if (
                    isinstance(checkpoint, dict) and 'state_dict' in checkpoint) else checkpoint

        # 3. æ¸…æ´—æƒé‡é”®å
        new_state_dict = {}
        for k, v in state_dict.items():
            name = k
            name = name.replace('module.', '').replace('Network.features.', '').replace('Network.classifier.', 'fc.')
            new_state_dict[name] = v

        # 4. ç¡®å®šç±»åˆ«æ•°é‡
        if 'fc.weight' in new_state_dict:
            model_num_classes = new_state_dict['fc.weight'].shape[0]
        elif 'classifier.3.1.weight' in new_state_dict:  # MobileNet
            model_num_classes = new_state_dict['classifier.3.1.weight'].shape[0]
        else:
            model_num_classes = len(classes)

        # 5. åˆå§‹åŒ–æ¨¡å‹æ¶æ„
        arch = MODEL_ARCH_CONFIG.get(dataset_name, "resnet18")

        if arch == "resnet50":
            model = models.resnet50(weights=None)
            model.fc = nn.Linear(model.fc.in_features, model_num_classes)

        elif arch == "mobilenet_v3_small":
            model = models.mobilenet_v3_small(weights=None)
            num_ftrs = model.classifier[3].in_features
            model.classifier[3] = nn.Sequential(
                nn.Dropout(p=0.3),
                nn.Linear(num_ftrs, model_num_classes)
            )

        else:  # é»˜è®¤ ResNet18
            model = models.resnet18(weights=None)
            model.fc = nn.Linear(model.fc.in_features, model_num_classes)

        # 6. åŠ è½½å‚æ•°
        model.load_state_dict(new_state_dict, strict=False)
        model.to(device)
        model.eval()

        _MODEL_CACHE[dataset_name] = (model, classes)
        return model, classes

    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹ {dataset_name} å´©æºƒ: {e}")
        import traceback
        traceback.print_exc()
        return None, []


def list_images(dataset_name):
    path = os.path.join("datasets", dataset_name)
    if not os.path.exists(path): return f"Error: {path} not found"
    images = []
    for root, _, files in os.walk(path):
        for f in files:
            if f.lower().endswith(('.png', '.jpg', '.jpeg')):
                images.append(os.path.join(root, f).replace('\\', '/'))
    return images


def classify_image(image_path):
    if "dataset_A" in image_path:
        ds = "dataset_A"
    elif "dataset_B" in image_path:
        ds = "dataset_B"
    elif "dataset_C" in image_path:
        ds = "dataset_C"
    else:
        return "Error: è·¯å¾„ä¸­æœªåŒ…å« dataset_A/B/C"

    model, classes = load_model_for_dataset(ds)
    if not model: return "Error: æ¨¡å‹åŠ è½½å¤±è´¥ (æŸ¥çœ‹ä¸Šæ–¹æŠ¥é”™)"

    try:
        # 1. è¯»å–åŸå§‹å›¾ç‰‡
        img = Image.open(image_path).convert('RGB')

        # ============================================================
        # ğŸŒ‘ æ ¸å¿ƒä¿®æ”¹ï¼šé’ˆå¯¹ dataset_C çš„è‡ªåŠ¨é»‘åº•è½¬æ¢é€»è¾‘
        # ============================================================
        if ds == "dataset_C":
            # è®¡ç®—å›¾ç‰‡å¹³å‡äº®åº¦ (0=å…¨é»‘, 255=å…¨ç™½)
            gray_img = img.convert('L')
            stat = ImageStat.Stat(gray_img)
            avg_brightness = stat.mean[0]

            # é˜ˆå€¼è®¾ä¸º 100ï¼š
            # å¦‚æœäº®åº¦ > 100 (è¯´æ˜æ˜¯ç™½çº¸æˆ–è€…äº®è‰²èƒŒæ™¯)ï¼Œåˆ™æ‰§è¡Œåè‰² -> å˜æˆé»‘åº•
            # å¦‚æœäº®åº¦ < 100 (è¯´æ˜å·²ç»æ˜¯é»‘åº•äº†)ï¼Œåˆ™ä¿æŒä¸å˜
            if avg_brightness > 100:
                # print(f"  [Auto-Fix] æ£€æµ‹åˆ°ç™½åº•å›¾ (äº®åº¦{avg_brightness:.0f}) -> è‡ªåŠ¨åè‰²ä¸ºé»‘åº•")
                img = ImageOps.invert(img)
        # ============================================================

        img_t = transform(img).unsqueeze(0).to(device)

        with torch.no_grad():
            out = model(img_t)
            prob = torch.nn.functional.softmax(out[0], dim=0)
            score, idx = torch.max(prob, 0)

            if idx.item() >= len(classes):
                return f"Error: ç´¢å¼•è¶Šç•Œ"

            class_name = classes[idx.item()]
            confidence = score.item() * 100

            return f"{class_name} ({confidence:.1f}%)"

    except Exception as e:
        return f"Error: {e}"