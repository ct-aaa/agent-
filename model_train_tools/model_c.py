import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms, datasets
from torch.utils.data import DataLoader, Dataset
from PIL import Image, ImageOps, ImageFilter
import os
import glob

# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================
# 1. ä½ çš„â€œè€ƒè¯•é¢˜â€ (åªæœ‰ä¸€å¼ å›¾çš„æ•°æ®é›†)
DATA_C_DIR = "../datasets/dataset_C"

# 2. ä½ çš„â€œæ•™ç§‘ä¹¦â€ (TU-Berlin å®Œæ•´æ•°æ®é›†)
DATA_TU_DIR = "../datasets/dataset_TU"

# 3. æƒé‡è·¯å¾„
PRETRAINED_PATH = "pre_train/model_best_TUBerlin.pth"

# 4. ä¿å­˜ä½ç½®
MODEL_SAVE_DIR = "../models"
MODEL_SAVE_PATH = os.path.join(MODEL_SAVE_DIR, "best_model_trained_on_TU_tested_on_C.pth")

BATCH_SIZE = 32
EPOCHS = 10
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# ===============================================

# === 1. è§†è§‰å¢å¼ºé¢„å¤„ç† (ä¿æŒä¸å˜ï¼Œå› ä¸ºæ•ˆæœå¾ˆå¥½) ===
class SketchEnhancement(object):
    def __call__(self, img):
        if img.mode != 'RGB':
            img = img.convert('RGB')
        img = ImageOps.invert(img)  # åè½¬é¢œè‰²
        fn = lambda x: 255 if x > 50 else 0
        img = img.convert('L').point(fn, mode='1').convert('RGB')  # äºŒå€¼åŒ–
        # img = img.filter(ImageFilter.MaxFilter(3)) # è†¨èƒ€ (TUæ•°æ®æœ¬èº«çº¿æ¡è¾ƒå¥½ï¼Œå¯æ ¹æ®æƒ…å†µå¼€å…³)
        return img


# === 2. è‡ªå®šä¹‰æ•°æ®é›†ç±»ï¼šåªåŠ è½½ TU-Berlin ä¸­æŒ‡å®šçš„ç±»åˆ« ===
class FilteredTUDataset(Dataset):
    def __init__(self, tu_root_dir, target_classes, transform=None):
        """
        tu_root_dir: TU-Berlin æ ¹ç›®å½•
        target_classes: æˆ‘ä»¬å…³å¿ƒçš„é‚£ 20 ä¸ªç±»åˆ«çš„åå­—åˆ—è¡¨ ['bed', 'bee', ...]
        """
        self.transform = transform
        self.samples = []  # å­˜å‚¨ (å›¾ç‰‡è·¯å¾„, æ ‡ç­¾ID)
        self.classes = target_classes

        # å»ºç«‹ ç±»åˆ«å -> ID çš„æ˜ å°„ (ç¡®ä¿å’Œ dataset_C ä¸€è‡´)
        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(target_classes)}

        print(f"ğŸ” æ­£åœ¨ä» TU-Berlin ç­›é€‰æ•°æ®...")
        count = 0
        for class_name in target_classes:
            class_dir = os.path.join(tu_root_dir, class_name)
            if not os.path.exists(class_dir):
                print(f"   âš ï¸ è­¦å‘Š: TU-Berlin ä¸­æ‰¾ä¸åˆ°ç±»åˆ« {class_name}ï¼Œè·³è¿‡ï¼")
                continue

            # æ‰¾æ‰€æœ‰å›¾ç‰‡
            images = glob.glob(os.path.join(class_dir, "*.png")) + \
                     glob.glob(os.path.join(class_dir, "*.jpg"))

            label_idx = self.class_to_idx[class_name]
            for img_path in images:
                self.samples.append((img_path, label_idx))
                count += 1

        print(f"âœ… ç­›é€‰å®Œæˆï¼å…±åŠ è½½ {count} å¼ è®­ç»ƒå›¾ç‰‡ (æ¶µç›– {len(target_classes)} ç±»)")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        img = Image.open(path).convert('RGB')
        if self.transform:
            img = self.transform(img)
        return img, label


# === æƒé‡åŠ è½½å‡½æ•° ===
def load_github_weights_fixed(model, path):
    if not os.path.exists(path): return model
    print(f"ğŸ“¥ åŠ è½½åŸºç¡€æƒé‡: {path}")
    checkpoint = torch.load(path, map_location=DEVICE, weights_only=False)
    state_dict = checkpoint['state_dict'] if (
                isinstance(checkpoint, dict) and 'state_dict' in checkpoint) else checkpoint
    new_state_dict = {}
    for k, v in state_dict.items():
        name = k.replace('Network.features.', '').replace('module.', '')
        if 'classifier' not in k and 'fc' not in name:
            new_state_dict[name] = v
    model.load_state_dict(new_state_dict, strict=False)
    return model


def main():
    os.makedirs(MODEL_SAVE_DIR, exist_ok=True)

    # --- 1. è·å–ç›®æ ‡ç±»åˆ«åˆ—è¡¨ (ä»¥ dataset_C ä¸ºå‡†) ---
    if not os.path.exists(DATA_C_DIR):
        print("âŒ æ‰¾ä¸åˆ° dataset_C")
        return

    # è‡ªåŠ¨è¯»å– dataset_C ä¸‹çš„æ–‡ä»¶å¤¹åä½œä¸ºç›®æ ‡ç±»åˆ«
    target_classes = sorted([d for d in os.listdir(DATA_C_DIR) if os.path.isdir(os.path.join(DATA_C_DIR, d))])
    print(f"ğŸ¯ ç›®æ ‡ç±»åˆ« ({len(target_classes)}): {target_classes}")

    # --- 2. å‡†å¤‡æ•°æ®å¢å¼º ---
    # è®­ç»ƒé›† (TUæ•°æ®): åŠ å¼ºæ‰°åŠ¨ï¼Œè®©æ¨¡å‹è§è¿‡ä¸–é¢
    train_transform = transforms.Compose([
        SketchEnhancement(),
        transforms.Resize(256),
        transforms.RandomCrop(224),  # éšæœºè£å‰ª
        transforms.RandomHorizontalFlip(),  # éšæœºç¿»è½¬
        transforms.RandomRotation(15),  # éšæœºæ—‹è½¬ (å¾ˆé‡è¦ï¼Œå¢åŠ æ³›åŒ–æ€§)
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # éªŒè¯é›† (Cæ•°æ®): ä¿æŒç¨³å®šï¼Œåªåšå¿…è¦çš„ç¼©æ”¾
    val_transform = transforms.Compose([
        SketchEnhancement(),
        transforms.Resize(240),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # --- 3. æ„å»ºæ•°æ®é›† ---
    # è®­ç»ƒé›†ï¼šæ¥è‡ª TU-Berlin (ç­›é€‰ç‰ˆ)
    train_dataset = FilteredTUDataset(DATA_TU_DIR, target_classes, transform=train_transform)

    # éªŒè¯é›†ï¼šæ¥è‡ª Dataset_C (å…¨é‡éªŒè¯)
    val_dataset = datasets.ImageFolder(DATA_C_DIR, transform=val_transform)

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

    # --- 4. æ¨¡å‹åˆå§‹åŒ– ---
    print("ğŸ› ï¸ åˆå§‹åŒ–æ¨¡å‹...")
    model = models.resnet50(weights=None)
    model = load_github_weights_fixed(model, PRETRAINED_PATH)

    # æ›¿æ¢æœ€åä¸€å±‚ä¸º 20 ç±»
    model.fc = nn.Linear(model.fc.in_features, len(target_classes))
    model = model.to(DEVICE)

    # --- 5. è®­ç»ƒ ---
    optimizer = optim.Adam(model.parameters(), lr=1e-4)
    criterion = nn.CrossEntropyLoss()

    best_acc = 0.0
    print(f"ğŸ‘Š å¼€å§‹è·¨åŸŸè®­ç»ƒ (Train: TU-Berlin -> Test: Dataset_C)...")

    for epoch in range(EPOCHS):
        # è®­ç»ƒ
        model.train()
        train_loss = 0.0
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        # éªŒè¯ (è€ƒè¯•)
        model.eval()
        correct = 0
        total = 0
        debug_log = []
        with torch.no_grad():
            for i, (inputs, labels) in enumerate(val_loader):
                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (preds == labels).sum().item()

                # è®°å½•ä¸€ä¸‹é¢„æµ‹é”™è¯¯çš„æ ·æœ¬ï¼Œæ–¹ä¾¿çœ‹
                if i == 0:
                    # åªçœ‹ç¬¬ä¸€ä¸ª batch é‡Œçš„é”™é¢˜
                    wrong_idx = (preds != labels).nonzero(as_tuple=True)[0]
                    for idx in wrong_idx:
                        if len(debug_log) < 3:  # åªè®°å‰3ä¸ª
                            true_cls = target_classes[labels[idx].item()]
                            pred_cls = target_classes[preds[idx].item()]
                            debug_log.append(f"âŒ é”™æŠŠ [{true_cls}] è®¤æˆ [{pred_cls}]")

        val_acc = 100 * correct / total
        avg_loss = train_loss / len(train_loader)

        print(f"Epoch {epoch + 1:02d} | Train Loss: {avg_loss:.4f} | ğŸ¯ Dataset_C Acc: {val_acc:.2f}%")
        if debug_log:
            print(f"   é”™é¢˜æœ¬: {debug_log}")

        if val_acc > best_acc:
            best_acc = val_acc
            torch.save(model.state_dict(), MODEL_SAVE_PATH)
            print(f"   ğŸ† æ–°é«˜åˆ†ï¼æ¨¡å‹å·²ä¿å­˜ã€‚")

    print(f"ğŸ‰ ç»“æŸï¼æœ€ä½³æˆç»©: {best_acc:.2f}%")


if __name__ == "__main__":
    main()